---
title: "test"
author: "Nick McManus"
date: "2023-07-21"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)    ## always
library(zoo)          ## interpolation
library(here)         ## consistent file paths
library(stringr)      ## split up file names
library(lubridate)    ## mutate dates
library(terra)        ## better/faster GIS package
library(sf)           ## format plays nicer w/leaflet
library(raster)       ## format plays nicer w/leaflet
library(leaflet)      ## test interactive maps
```


## DATA WRANGLING

In this section, we'll crop and reproject spatial data as well as find zonal statistics and output dataframes useful for the Shiny.



### Zip codes

We want to find and save the zip codes located within the Central Valley portion of Kern county. This .shp will then be exported for use in the Shiny app.

*Note*: For the purposes of this app, the extent of zip codes will be cropped to only portions within both Kern county and the Central Valley. To remove artifacts of zip code portions that only slightly intersect with Kern, we'll also remove any zip code with an area below 1,000,000 m^2. To keep the entire geometry of zips that are within Kern, see the commented out code chunk below. 
```{r}
## Read in data w/ 'sf' pkg (easier to filter by attribute).
## After filtering, make SpatVect obj (`terra` pkg)

kern <- st_read(here('data/counties_ca/cnty19_1.shp')) %>% 
  ## Only keep kern county
  dplyr::filter(COUNTY_NAM == "Kern") %>%
  dplyr::select(COUNTY_NAM) %>% 
  terra::vect() 

valley <- st_read(here('data/central_valley/Alluvial_Bnd.shp')) %>% 
  st_transform(crs = st_crs(kern)) %>% 
  vect() %>% 
  ## Only keep portion w/in Kern
  terra::intersect(kern)

zips <- st_read(here('data/zipcodes/CA_Zips.shp')) %>% 
  st_transform(crs = st_crs(kern)) %>% 
  vect() %>% 
  terra::intersect(valley) %>% 
  st_as_sf() %>% 
  dplyr::select(GEOID10) %>% 
  rename(zipcode = GEOID10) %>% 
  ## best crs for calculating area(?)
  st_transform(crs = "epsg:3310")

## find area and remove small cropped zips
zips_filter <- zips %>% 
  mutate(area_m2 = as.numeric(st_area(zips))) %>% 
  filter(area_m2 >= 1000000) %>% 
  vect()

## ensure CRS is leaflet friendly
kern_zips <- terra::project(zips_filter, "+proj=longlat +datum=WGS84")

## Save clipped zips
writeVector(kern_zips, here('data/zipcodes/kern_zips.shp'), overwrite = T)

## Save Kern and Valley vect for leaflet too
kern <- terra::project(kern, "+proj=longlat +datum=WGS84")
writeVector(kern, here('data/counties_ca/kern.shp'), overwrite = T)

valley <- terra::project(valley, "+proj=longlat +datum=WGS84")
writeVector(valley, here('data/central_valley/valley.shp'), overwrite = T)

```

```{r}
# ## Read in raw data
# zips <- st_read(here('data/zipcodes/CA_Zips.shp'))
# counties <- st_read(here('data/counties_ca/cnty19_1.shp')) 
# 
# ## make sure both layers have same crs
# zips_trans <- zips %>% 
#   st_transform(zips, crs = st_crs(counties)) %>%
#   ## only need to keep zipcode number
#   dplyr::select(GEOID10) 
# 
# ## Only keep name of counties
# counties <- dplyr::select(counties, COUNTY_NAM)
# 
# # kern <- dplyr::filter(counties, COUNTY_NAM == "Kern") 
# 
# 
# ## Keep zipcodes that touch Kern county
# kern_zips <- st_join(zips_trans, counties, join = st_intersects) %>% 
#   dplyr::filter(COUNTY_NAM == "Kern", 
#                 ## remove select zips that barely touch Kern
#                 !GEOID10 %in% c(93536, 93535, 93201, 
#                                 93239, 93204, 93453,
#                                 93257, 93260, 93219, 
#                                 93261, 93218)) 
#   
# ## Reproject zips to leaflet-required crs
# kern_zips_trans <- st_transform(kern_zips, crs = "+proj=longlat +datum=WGS84")
# 
# ## save
# st_write(kern_zips_trans, here("data/zipcodes/kern_zips.shp"))

```


### Standing water

#### Convert to .tif
First we need to deal with format of the 2022 Landsat rasters. These are unmarked files types (no file extension) paired with an .hdr file. The unmarked file can only be read with the .hdr file present of the same name. This will make future steps of reading in layers tricky, so first we'll convert all these files to .tif format and remove the original file pairings. 
```{r}
convert_tif = function(path) {
  ## List the non .hdr files (can't be read in)
  list <- grep(list.files(path), pattern = ".hdr", invert = TRUE, value = TRUE)
  
  ## Read in and save as .tif
  for (i in 1:length(list)) {
    r = rast(paste0(path, list[i]))
    writeRaster(r, paste0(path,list[i],".tif"), overwrite = T)
  }
  
  ## List and remove original non .tif files
  nontifs <- grep(list.files(path, full.names = TRUE), 
                  pattern = ".tif", invert = TRUE, value = TRUE)
  file.remove(nontifs)
}

convert_tif(path = here("data/water/Landsat_Dan/p042r035/2022//"))

```

#### Merge images
Our AOI is split between two Landsat images (rows 35 and row 36 within path 42). First we'll merge them by date, reproject to the crs for Leaflet, and crop to Kern county. 
```{r}
## kern county
kern <- vect(here("data/counties_ca/kern.shp"))

## Create paths for water rasters and masks
path35 <- here('data/water/Landsat_Dan/p042r035/2022//')
path36 <- here('data/water/Landsat_Dan/p042r036/2022//')

## Fxn to extract dates based on LANDSAT naming convention
dates <- function(files) {
  str_split(files, "_", simplify = TRUE) %>% 
  as.data.frame() %>%
  mutate(date = lubridate::ymd(V4)) %>%
  dplyr::select(date)
}

## df with all files and dates
waterInput_df <- data.frame("rast35" = list.files(path35, pattern="UnmixedMask85"),
                            "mask35" = list.files(path35, pattern = "QA_PIXEL"),
                            "rast36" = list.files(path36, pattern="UnmixedMask85"),
                            "mask36" = list.files(path36, pattern="QA_PIXEL")) %>%
  ## extract date from r35
  mutate(dates(rast35),
         date = as.character(date))

## Fxn to mask, merge, then export for each date
waterMerge <- function(rast35, mask35, rast36, mask36, date, kern, pathOut) {
  ## raster and mask for row 35 -------------  
  r35 <- rast(paste0(path35, rast35))
  names(r35) <- "rast"
  m35 <- rast(paste0(path35, mask35))
  ## mask values of 1 are NA
  m35[m35 == 1] <- NA
  ## mask raster 35
  r_masked35 <- terra::mask(r35, m35)
 
  ## raster and mask for row 36 ---------------
  r36 <- rast(paste0(path36, rast36))
  names(r36) <- "rast"
  m36 <- rast(paste0(path36, mask36))
  ## mask values of 1 are NA
  m36[m36 == 1] <- NA
  ## mask raster 36
  r_masked36 <- terra::mask(r36, m36)
 
  ## merge rasts using SpatRastCollection
  s <- sprc(r_masked35, r_masked36)
  m <- merge(s)
  

  ## reproject kern to crs of raster bc faster
  kern_reproj = project(kern, y = crs(m))
  ## crop merged rast to kern county
  m_kern = crop(m, kern_reproj)
 
  terra::writeRaster(m_kern, filename = paste0(pathOut, "p42_kern_", date, ".tif"))
}

## Run fxn for all files in directory
pmap(waterInput_df, waterMerge, kern=kern,
     pathOut = here("data/water/p042_masked_merged/2022//"), 
     .progress = TRUE)
```


#### Zonal stats
Here we determine how much standing water is present within each zip code for each image date. The larger `waterZonal()` fxn (which contains several more fxns inside) reads in our rasters and vector of interest, reprojects where needed, and iterates the zonal function over all the rasters in a given directory. We'll run this fxn for 2023 and 2022 rasters, then merge the results and export a single .csv.
```{r}
waterZonal <- function(rastPath, vect) {
    ## Fxn to get dates
    dates <- function(files) {
      str_split(files, "_", simplify = TRUE) %>% 
      as.data.frame() %>%
      mutate(date = lubridate::ymd(V3)) %>%
      dplyr::select(date)
    }
    
    ## One df with all files and dates
    df <- data.frame("rasts" = list.files(rastPath, pattern="kern")) %>% 
      ## extract date from r35
      mutate(dates(rasts),
             rasts = paste0(rastPath, rasts))
    
    ## Need same crs for zonal stats.
    ## Easier to transform vector than the high-res raster
    r <- rast(df$rasts[1])
    vect <- project(vect, y = crs(r))
    
    ## Fxn to perform zonal stats and output results
    zonalFxn <- function(rasts, vect, date) {
      r = terra::rast(rasts)
      zonalStat <- terra::zonal(r, vect, fun = 'sum', na.rm = TRUE)
      zonalStat_df <- zonalStat %>%
        ## assign values with corresponding zipcode
        mutate(zipcode = vect$zipcode, .before = 1) %>%
        ## convert values from # of pixels to acres
        ## w/30m resolution, each pixel is 900 m^2
        ## 4046.86 m^2 are in one acre
        rename(ncells = "rast") %>%
        mutate(acres = ncells * 900 / 4046.86) %>%
        ## finally, add date image was taken
        mutate(date = date)
    }
    
    ## Run fxn over list w/pmap
    waterStats_df <- pmap_dfr(df, zonalFxn, vect=vect, 
                              .progress = TRUE)
    
} ##END FXN

## Paths for water rasters and zipcode vector
path23 <- here('data/water/p042_masked_merged/2023//')
path22 <- here('data/water/p042_masked_merged/2022//')
vect <- vect(here("data/zipcodes/kern_zips.shp"))

## Run fxn for 2023 and 2022 and bind results to one df
waterStats_df = rbind(waterZonal(rastPath=path23, vect=vect),
                      waterZonal(rastPath=path22, vect=vect))

## export as .csv
write_csv(waterStats_df, here('data/water/water_acre_zipcode.csv'))
```

There are some cloud issues with masking for standing water. The values for select dates will be replaced by an averaged value from the date prior and following.
```{r}
waterStats_df = read_csv(here("data/water/water_acre_zipcode.csv"))

water_int_df = waterStats_df %>% 
  group_by(zipcode) %>% 
  ## For three dates, just avg values directly before/after
  mutate(acres_int = case_when(date %in% c("2023-04-22",
                                           "2023-06-09",
                                           "2023-07-03") 
                               ~((lead(acres, n = 1)+lag(acres, n = 1))/2),
                               ## B/c these dates are sequential, replace w/NA then interpolate
                               date %in% c("2023-05-08",
                                           "2023-05-16") 
                               ~NA,
                               .default = acres)) %>% 
  mutate(acres_int = na.approx(acres_int)) %>% 
  mutate(ncells_int = case_when(date %in% c("2023-04-22",
                                           "2023-06-09",
                                           "2023-07-03") 
                                ~(round(((lead(ncells, n = 1)+lag(ncells, n = 1))/2),0)),
                               ## B/c these dates are sequential, replace w/NA then interpolate
                               date %in% c("2023-05-08",
                                           "2023-05-16") 
                               ~NA,
                               .default = ncells)) %>%   
  mutate(ncells_int = round(na.approx(ncells_int),0))

write_csv(water_int_df, here("data/water/water_acre_zipcode.csv"))

```


#### Water GIF
To stack for a .gif, rasters must be same extent, resolution, and number of rows/columns. First we'll merge path42 rasters by year to determine the common extent between all. Then, each raster will be resampled to have this identical extent, stacked, and saved.

```{r}
## To stack for gif, need the same extent.
## Each image slightly different bc of satellite path.
## Merge all the p42 rasts to find overall extent, then use to crop
rasts = list.files(here("data/water/p042_masked_merged/2023"),
                   pattern = "kern",
                   full.names = T)

## Read in every raster and merge them
for (i in 1:length(rasts)) {
  r = rast(rasts[i])
  assign(paste0("rast", i), r)
}
## create rast collection
s <- sprc(rast1, rast2, rast3, rast4, rast5, rast6, rast7,
          rast8, rast9, rast10, rast11, rast12, rast13, rast14)
## merge rast collection, then reproj to leaflet crs
m <- merge(s) %>% 
  project(y = crs("epsg:900913"))
## read in Kern shp
kern <- vect(here("data/counties_ca/kern.shp")) %>% 
  project(y = crs(m))

## Now change the extent of every raster to that of the merged one
## and make all 0 values NA (transparent for leaflet map)
for (i in 1:length(rasts)) {
  r = rast(rasts[i]) %>% 
    project(y = crs(m))
  resamp <- resample(r, m, method="near")
  values(resamp)[values(resamp) < 1] <- NA
  assign(paste0("rast", i), resamp)
}

## Stack and export
stack = c(rast1, rast2, rast3, rast4, rast5, rast6, rast7,
          rast8, rast9, rast10, rast11, rast12, rast13, rast14)

writeRaster(stack, here("data/water/p042_masked_merged/p42_2023_stack.tif"),
            overwrite = TRUE)
```

test animated plot
```{r}

r = stack(here("data/water/p042_masked_merged/p42_2023_stack.tif"))
r1 = r$rast.1

test = projectRaster(r1, crs = "epsg:900913")

library(webshot)
library(htmltools)
library(leaflet)

leaflet() %>% 
  addProviderTiles(providers$Esri.WorldImagery) %>%
  addRasterImage(test, colors = "dodgerblue4", project =F)



```



### Temperature

The mean daily temperature by zip code was extracted from the PRISM dataset using a Google Earth Engine script. This was exported as a CSV with variables for date ("imageID"), zip code ("GEOID10"), and daily mean temperate ("mean"). We'll read in and clean up the CSV, as well as determine if each observation falls w/in the optimal range for WNV transmission. For *Culex tarsalis*, this is between 22.9-25.9C (optimum temp of 23.9 w/95% CI); for *Culex quinquefasciatus*, this is between 23.9-27.1C (optimum 25.2 w/95% CI). Becuse both species are present in Kern, we'll consider the optimal range from 22.9-27.1C (Shocket et al., 2020)
```{r}
temp <- read_csv(here('data/temp/kern_tmean_GEE_output.csv'))

temp2 <- temp %>% 
  ## extract date from PRISM image id
  mutate(date = lubridate::ymd(imageID)) %>% 
  dplyr::select(!imageID) %>% 
  ## rename GEE extract variables
  rename(tmean_c = mean,
         zipcode = GEOID10) %>% 
  ## find temp in F
  mutate(tmean_f = (tmean_c*(9/5))+32,
         .before = date) %>% 
  ## does a day fall w/in optimal temp range?
  mutate(cx_opt = case_when(tmean_c >= 12.1 & tmean_c < 22.9 ~ "in range",
                            tmean_c >= 22.9 & tmean_c <= 27.1 ~ "optimal",
                            tmean_c > 27.1 & tmean_c <=31.9 ~ "in range",
                            .default = "out range")) %>% 
  ## set T/F as factor for consistent graphic
  mutate(cx_opt = fct_relevel(cx_opt, levels = c("optimal", "in range", "out range")))

write_csv(temp2, here('data/temp/kern_tmean_20180101_20230731.csv'))


temp3 <- temp2 %>% 
  filter(zipcode == 93252,
         date >= "2022-01-01" & date <= "2022-07-31")

test <- temp3 %>% 
  group_by(culex_range) %>% 
  summarize(count = sum(culex_range == "TRUE", na.rm = T))

ggplot(data = temp3, aes(x = date, y = tmean_f)) +
    geom_rect(xmin = -Inf, xmax = Inf, ymax = 78.6, ymin = 73.2,
            alpha = 0.01, fill = "gray75")+
        geom_point(size = 3, 
                   alpha = 0.7,
                   aes(color = cxTar_opt)) +
        scale_color_manual(name = "",
                           values = c("coral2", "dodgerblue"),
                           labels = c("", "In range"))+
        geom_line(linewidth = 0.7) +
        labs(y = "Mean daily temperature (F)",
             x = "Date") +
        scale_x_date(date_labels = "%b %y") +
        geom_hline(yintercept = 73.2, linetype = "dashed", color = "gray50")+
        geom_hline(yintercept = 78.6, linetype = "dashed", color = "gray50")+
  annotate("text", y = 74, x = as.Date(temp3$date[1]), 
           hjust = 0, vjust = 0,
           label = "Optimal range for\nWNV transmission",
           size = 3,
           fontface = "bold") +
        theme_classic() +
        theme(
          # axis.title.x = element_text(face = "bold", vjust = -1),
          axis.title.y = element_text(vjust = 2, size = 14),
          axis.title.x = element_text(vjust = -1, size = 14),
          axis.text = element_text(size = 13),
          legend.position = "none"
        )
```




### Trap data

Finally, we'll wrangle some trap data and aggregate it by zip code. Exact locations of traps should not be public, so instead we'll produce plots showing how the number of WNV positives found in traps across a zip code change by month/year.

Because trap data is aggregated and assigned to clusters, we'll first need to assign each cluster to a zip code. 
```{r}
clust <- read_sf(here("data/traps/shp_files/clusterPolys.shp"))

zips <- read_sf(here("data/zipcodes/kern_zips.shp")) %>% 
  st_transform(crs = crs(clust))

clust_zips <- st_centroid(clust) %>% 
  st_join(zips) %>% 
  ## centroid of clust 9 *just* outside
  ## manually adding to zip 93280
  within(., zipcode[clust == 9] <- 93280) %>% 
  within(., area_m2[clust == 9] <- (zips$area_m2[zips$zipcode==93280]))
```


Andy's new data:
```{r}
## wnv infection
wnv <- read_csv(here('data/traps/wnvMIRPIR1500LagWeeks0_NA.csv')) %>% 
  janitor::clean_names() %>% 
  ## assign zip by clust
  inner_join(x = .,y = clust_zips) %>% 
  ## filter for relevant vars
  dplyr::select(zipcode, clust:woy, date, 
                pool_size, num_pools, mir_all, mir_spline_all) %>%
  mutate(month = lubridate::month(date),
         .before = year)
write_csv(wnv, here("data/traps/wnvMIR_plotting.csv"))


### abundance
abund <- read_csv(here('data/traps/all1500LagWeeks0_NA.csv')) %>% 
  janitor::clean_names() %>% 
  ## assign zip by clust
  inner_join(x=., y=clust_zips) %>% 
  ## filter for relevant vars
  dplyr::select(zipcode, clust:woy, collection_date, mos_per_trap_night) %>% 
  rename(date = collection_date) %>% 
  mutate(month = lubridate::month(date),
         .before = year)
write_csv(abund, here("data/traps/abundance_plotting.csv"))
```



TEST WRANGLING/PLOTS:
MIR:
```{r}
wnv <- read_csv(here("data/traps/wnvMIR_plotting.csv"))

zip = 93203

cases_zip_yr <- wnv %>% 
  filter(zipcode == zip, 
         date >= "2022-01-01" & date <= "2022-04-01") %>% 
  group_by(year, date) %>% 
  summarize(avgMIR = mean(mir_all, na.rm = TRUE))

zip_avg_cases <- wnv %>% 
  filter(zipcode == zip) %>% 
  group_by(woy) %>% 
  summarize(avg = mean(mir_all, na.rm = TRUE))

kern_avg_cases <- wnv %>% 
  group_by(woy) %>% 
  summarize(avg = mean(mir_all, na.rm = TRUE))

zip_avgMIR <- wnv %>%  
  filter(zipcode==zip)
zip_avgMIR <- mean(zip_avgMIR$mir_all, na.rm = TRUE)

kern_avgMIR <- mean(wnv$mir_all, na.rm = TRUE)

ggplot()+
  ## time frame in zip code
  geom_col(data = cases_zip_yr, 
             aes(x=date, y = avgMIR),
            fill = "sienna2", color = "sienna4") +
  # ## avg zipcode
  # geom_point(data = zip_avg_cases, 
  #            aes(x=woy, y = avg),
  #            color = "plum", size = 3, alpha = 0.6) +
  # geom_line(data = zip_avg_cases, 
  #            aes(x=woy, y = avg),
  #           color = "plum4") +
  # ## avg kern
  # geom_point(data = kern_avg_cases, 
  #            aes(x=woy, y = avg),
  #            color = "gray50", size = 3, alpha = 0.6) +
  # geom_line(data = kern_avg_cases, 
  #            aes(x=woy, y = avg),
  #           color = "black") +
  labs(y = "Average MIR",
       x = element_blank()) +
  theme_classic() +
  theme(
    # axis.title.x = element_text(face = "bold", vjust = -1),
    axis.title.y = element_text(face = 'bold', vjust = 3)
  )

```

Abundance:
```{r}
abund <- read_csv(here("data/traps/abundance_plotting.csv"))

zip = 93249

if (length(abund_cust$avg) == 0) {
  print("no data")
}

abund_cust <- abund %>% 
  filter(zipcode == zip, 
         date >= "2032-01-01" & date <= "2032-12-31") %>% 
  group_by(year, date) %>% 
  summarize(avg = mean(mos_per_trap_night, na.rm = TRUE))

zip_avg_abund <- abund %>% 
  filter(zipcode == zip) %>% 
  group_by(woy) %>% 
  summarize(avg = mean(mos_per_trap_night, na.rm = TRUE))

kern_avg_abund <- abund %>% 
  group_by(woy) %>% 
  summarize(avg = mean(mos_per_trap_night, na.rm = TRUE))

## avg values
cust_avgAbund <- abund %>% 
  filter(zipcode == zip,
         date >= "2022-01-01" & date <= "2022-12-31")
cust_avgAbund <- mean(cust_avgAbund$mos_per_trap_night, na.rm = TRUE)

zip_avgAbund <- abund %>%  
  filter(zipcode==zip)
zip_avgAbund <- mean(zip_avgAbund$mos_per_trap_night, na.rm = TRUE)

kern_time_avgAbund <- abund %>% 
  filter(date >= "2022-01-01" & date <= "2022-12-31")
kern_time_avgAbund <- mean(kern_time_avgAbund$mos_per_trap_night, na.rm = TRUE)


## abundance comp (filled)
ggplot()+
  ## avg kern
  geom_point(data = kern_avg_abund,
             aes(x=woy, y = avg),
             color = "gray30", size = 2.5, alpha = 0.6) +
  geom_line(data = kern_avg_abund,
             aes(x=woy, y = avg),
            color = "black", linewidth = 0.6) +
  geom_area(data = kern_avg_abund,
            aes(x=woy, y = avg),
            fill = "gray60", alpha=.4)+
   # avg zipcode
  geom_point(data = zip_avg_abund,
             aes(x=woy, y = avg),
             color = "plum", size = 2.5, alpha = 0.8) +
  geom_line(data = zip_avg_abund,
             aes(x=woy, y = avg),
            color = "purple4", linewidth = 0.7) +
   geom_area(data = zip_avg_abund,
             aes(x=woy, y = avg),
            fill = "plum", alpha=.5) +
  ## user defined zip and time
   geom_point(data = abund_cust, 
             aes(x=woy, y = avg),
             color = "sienna2", size = 2.5, alpha = 0.8) +
  geom_line(data = abund_cust, 
             aes(x=woy, y = avg),
            color = "sienna4", linewidth = 0.7) +
  geom_area(data = abund_cust, 
             aes(x=woy, y = avg),
            fill = "sienna2", alpha = .5) +
  labs(y = "Average weekly abundance",
       x = element_blank()) +
  theme_classic() +
  theme(
    # axis.title.x = element_text(face = "bold", vjust = -1),
    axis.title.y = element_text(face = 'bold', vjust = 3)
  )


## abundance comp (lines)
ggplot()+
  ## avg kern (in time period)
  geom_hline(yintercept = kern_time_avgAbund,
            color = "black", linetype = "dashed", linewidth = 0.8) +
  # annotate("text", y = (kern_time_avgAbund+0.07), x = abund_cust$date[1],
  #          hjust = 0,
  #          label = "Average abundance within time period",
  #          size = 3,
  #          fontface = "bold") +
   # avg zipcode
  geom_hline(yintercept = zip_avgAbund,
            color = "purple", linetype = "dashed", linewidth = 0.8) +
  # annotate("text", y = (zip_avgAbund+0.07), x = abund_cust$date[1],
  #          hjust = 0,
  #          label = "Average abundance across zip code",
  #          size = 3,
  #          color = "purple4",
  #          fontface = "bold") +
  ## user defined zip/year
   geom_point(data = abund_cust, 
             aes(x=date, y = avg),
             color = "sienna2", size = 3, alpha = 0.7) +
  geom_line(data = abund_cust, 
             aes(x=date, y = avg),
            color = "sienna4", linewidth = 0.8) +
  # geom_hline(yintercept = cust_avgAbund,
  #            color = "sienna", linetype= "dashed", linewidth = 0.8)+
  # annotate("text", y = (cust_avgAbund+0.07), x = abund_cust$date[1],
  #          hjust = 0,
  #          label = "Average abundance for zipcode and time period",
  #          size = 3,
  #          color = "sienna4",
  #          fontface = "bold") +
  # geom_area(data = abund_cust, 
  #            aes(x=woy, y = avg),
  #           fill = "sienna2", alpha = .5) +
  labs(y = "Average weekly abundance",
       x = element_blank()) +
  scale_x_date(date_labels = "%b %y",
               date_breaks = "1 month") +
  theme_classic() +
  theme(
    # axis.title.x = element_text(face = "bold", vjust = -1),
    axis.title.y = element_text(face = 'bold', vjust = 3),
    legend.position = "right"
  )
```


### Transmission efficiency

Here we'll find an average WNV transmission efficiency for each zipcode.
*NOTE:* This may be replaced by R0 once the model is done.
```{r}
## Read in data
wnv_trans <- rast(here('data/Kern_transmission_raster_wgs84.tif'))

## easier to transform vector than high-res raster
kern_zips <- vect(here("data/zipcodes/kern_zips.shp")) %>% 
  project(y = crs(wnv_trans))

## find total average
trans_kern <- global(wnv_trans, "mean", na.rm = T)
trans_kern <- data.frame("trans_eff" = trans_kern[1,1], "zipcode" = "Kern")

## find the mean value per zip
trans_zonal <- terra::zonal(wnv_trans, kern_zips, fun = 'mean', na.rm = T)

trans_zonal_zips <- trans_zonal %>% 
  mutate(zipcode = kern_zips$zipcode) %>% 
  rename(trans_eff = Kern_transmission_raster_wgs84) %>% 
  rbind(., trans_kern)

write_csv(trans_zonal_zips, here('data/transmission_efficiency_zipcodes.csv'))
```



## TEST PLOTS



Testing out water plot for shiny:
```{r}
### ANIMATION?
library(xts)

date<-seq(as.Date("2015-01-01"), as.Date("2015-01-10"), by="day")
a<-xts(1:10,order.by=date)
df = data.frame(Lat = rnorm(1)+10, Long = rnorm(1),Id=a)

data_a<-data.frame(a)
data_a1<-data_a %>%  
  mutate("Lat" =as.numeric(df[1,1]),"Long"=as.numeric(df[2,1]),"Date"=rownames(data_a))
```


```{r}
data <- read_csv(here('data/water/water_acre_zipcode.csv'))

user_input <- "93311"

data_filtered <- data %>% 
  filter(zipcode == user_input)


ggplot(data_filtered, aes(x = date, y = water_acres)) +
  geom_point(color = "dodgerblue3", size = 4, alpha = 0.6) +
  geom_line(size = 0.6, color = "dodgerblue4") +
  labs(y = "Surface water size (ha)",
       x = element_blank()) +
    ## customize axis with cont 'date' class data
  scale_x_date(limits = as.Date(c('2023-03-13', '2023-06-25')),
               date_breaks = "1 week",
               date_labels = "%b %d") +
  theme_classic() +
  theme(
    # axis.title.x = element_text(face = "bold", vjust = -1),
    axis.title.y = element_text(face = 'bold', vjust = 3)
  )
```






```{r}
water <- raster(here('data/water/time_series/LC09_CU_003011_20230625_20230701_02_DSWE_Binary2_T.tif'))
water_reproj <- projectRaster(water, crs = crs(trans_r), method = 'ngb')
names(water_reproj) <- "water_reproj"
water_reproj[water_reproj == 0] <- NA

writeRaster(water_reproj, here('data/water/water_reproj.tif'))
```


Testing leaflet outside of Shiny app

```{r}
wnv_trans <- raster(here('data/Kern_transmission_raster_wgs84.tif'))

pal <- colorNumeric(palette = 'viridis', domain = values(wnv_trans),
                    reverse = TRUE,
                    na.color = "transparent")


zips <- read_sf(here("data/zipcodes/kern_zips.shp"))

leaflet() %>% 
  ## Add background maps
  addTiles(group = "OpenStreetMaps") %>% 
  addProviderTiles(providers$Stamen.TonerLite, group = "Toner Lite") %>%
  ## Add rasters
  addRasterImage(wnv_trans, colors = pal, project = FALSE, group = "WNV Risk") %>%
  # addRasterImage(water_reproj, colors = 'dodgerblue4', project = FALSE, group = "Water") %>% 
  ## Add polygons
  addPolygons(data = zips, color = "#343434", 
              weight = 2, fillOpacity = 0.2,
              label = paste0("Zip code: ", zips$zipcode),
              group = "Zip codes",
              highlightOptions = highlightOptions(weight = 5,
                                               color = "white",
                                               bringToFront = TRUE)) %>% 
  ## Add groups to map
  addLayersControl(
    baseGroups = c("OpenStreetMaps", "Toner Lite"),
    overlayGroups = c("WNV Risk", "Zip codes", "Water"),
    options = layersControlOptions(collapsed = T),
    position = "topleft"
  ) %>% 
  hideGroup("Zip codes") %>% 
  ## Add legend to map
  addLegend(pal = pal, values = values(wnv_trans),
            "bottomleft",
            title = "WNV Transmission Risk")%>% 
      setView(-119.3, 35.55, zoom = 11)

```

